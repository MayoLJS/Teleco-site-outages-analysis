{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Pandas Library to Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import/Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading first dataframe (total performance)\n",
    "performance_inclusion = pd.read_excel('C:/Users/mayow/OneDrive/My Projects [data analytics]/Telecommunications Site Outages Analysis and Reporting/assets/datasets/performance_and_outage_report.xlsx', sheet_name='Incl Exclusion')\n",
    "performance_inclusion.columns = performance_inclusion.iloc[0]\n",
    "performance_inclusion = performance_inclusion[1:].reset_index(drop=True)\n",
    "\n",
    "\n",
    "#Loading second dataframe (performance excluding external factors)\n",
    "performance_exclusion = pd.read_excel('C:/Users/mayow/OneDrive/My Projects [data analytics]/Telecommunications Site Outages Analysis and Reporting/assets/datasets/performance_and_outage_report.xlsx', sheet_name='Excl Exclusion')\n",
    "performance_exclusion.columns = performance_exclusion.iloc[0]\n",
    "performance_exclusion = performance_exclusion[1:].reset_index(drop=True)\n",
    "\n",
    "#Loading third dataframe (outages)\n",
    "outages = pd.read_excel('C:/Users/mayow/Downloads/Work - Offline/Performance - Lookup File/IHS Daily Performance.xlsx', sheet_name='Power TTs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [S/N, IHS Site ID, Site ID, MS/Colo Sites, Region IHS, Region state, REGION FOCUSED, State, Cluster, Regional Supervisor, Regional coordinator , Priority, Significant Priority class on site - All Customers, January Counts of PA<99.99, January Average Availability, 2023-01-01 00:00:00, 2023-01-02 00:00:00, 2023-01-03 00:00:00, 2023-01-04 00:00:00, 2023-01-05 00:00:00, 2023-01-06 00:00:00, 2023-01-07 00:00:00, 2023-01-08 00:00:00, 2023-01-09 00:00:00, 2023-01-10 00:00:00, 2023-01-11 00:00:00, 2023-01-12 00:00:00, 2023-01-13 00:00:00, 2023-01-14 00:00:00, 2023-01-15 00:00:00, 2023-01-16 00:00:00, 2023-01-17 00:00:00, 2023-01-18 00:00:00, 2023-01-19 00:00:00, 2023-01-20 00:00:00, 2023-01-21 00:00:00, 2023-01-22 00:00:00, 2023-01-23 00:00:00, 2023-01-24 00:00:00, 2023-01-25 00:00:00, 2023-01-26 00:00:00, 2023-01-27 00:00:00, 2023-01-28 00:00:00, 2023-01-29 00:00:00, 2023-01-30 00:00:00, 2023-01-31 00:00:00, Feburary  Counts of PA<99.99, Feburary Average Availability, 2023-02-01 00:00:00, 2023-02-02 00:00:00, 2023-02-03 00:00:00, 2023-02-04 00:00:00, 2023-02-05 00:00:00, 2023-02-06 00:00:00, 2023-02-07 00:00:00, 2023-02-08 00:00:00, 2023-02-09 00:00:00, 2023-02-10 00:00:00, 2023-02-11 00:00:00, 2023-02-12 00:00:00, 2023-02-13 00:00:00, 2023-02-14 00:00:00, 2023-02-15 00:00:00, 2023-02-16 00:00:00, 2023-02-17 00:00:00, 2023-02-18 00:00:00, 2023-02-19 00:00:00, 2023-02-20 00:00:00, 2023-02-21 00:00:00, 2023-02-22 00:00:00, 2023-02-23 00:00:00, 2023-02-24 00:00:00, 2023-02-25 00:00:00, 2023-02-26 00:00:00, 2023-02-27 00:00:00, 2023-02-28 00:00:00, 2024-02-29 00:00:00, March  Counts of PA<99.99, March Average Availability, 2023-03-01 00:00:00, 2023-03-02 00:00:00, 2023-03-03 00:00:00, 2023-03-04 00:00:00, 2023-03-05 00:00:00, 2023-03-06 00:00:00, 2023-03-07 00:00:00, 2023-03-08 00:00:00, 2023-03-09 00:00:00, 2023-03-10 00:00:00, 2023-03-11 00:00:00, 2023-03-12 00:00:00, 2023-03-13 00:00:00, 2023-03-14 00:00:00, 2023-03-15 00:00:00, 2023-03-16 00:00:00, 2023-03-17 00:00:00, 2023-03-18 00:00:00, 2023-03-19 00:00:00, 2023-03-20 00:00:00, 2023-03-21 00:00:00, ...]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 403 columns]\n",
      "*******************************\n",
      "Empty DataFrame\n",
      "Columns: [S/N, IHS Site ID, Site ID, MS/Colo Sites, Region IHS, Region state, REGION FOCUSED, State, Cluster, Regional Supervisor, Regional coordinator , Priority, Significant Priority class on site - All Customers, January Counts of PA<99.99, January Average Availability, 2023-01-01 00:00:00, 2023-01-02 00:00:00, 2023-01-03 00:00:00, 2023-01-04 00:00:00, 2023-01-05 00:00:00, 2023-01-06 00:00:00, 2023-01-07 00:00:00, 2023-01-08 00:00:00, 2023-01-09 00:00:00, 2023-01-10 00:00:00, 2023-01-11 00:00:00, 2023-01-12 00:00:00, 2023-01-13 00:00:00, 2023-01-14 00:00:00, 2023-01-15 00:00:00, 2023-01-16 00:00:00, 2023-01-17 00:00:00, 2023-01-18 00:00:00, 2023-01-19 00:00:00, 2023-01-20 00:00:00, 2023-01-21 00:00:00, 2023-01-22 00:00:00, 2023-01-23 00:00:00, 2023-01-24 00:00:00, 2023-01-25 00:00:00, 2023-01-26 00:00:00, 2023-01-27 00:00:00, 2023-01-28 00:00:00, 2023-01-29 00:00:00, 2023-01-30 00:00:00, 2023-01-31 00:00:00, Feburary  Counts of PA<99.99, Feburary Average Availability, 2023-02-01 00:00:00, 2023-02-02 00:00:00, 2023-02-03 00:00:00, 2023-02-04 00:00:00, 2023-02-05 00:00:00, 2023-02-06 00:00:00, 2023-02-07 00:00:00, 2023-02-08 00:00:00, 2023-02-09 00:00:00, 2023-02-10 00:00:00, 2023-02-11 00:00:00, 2023-02-12 00:00:00, 2023-02-13 00:00:00, 2023-02-14 00:00:00, 2023-02-15 00:00:00, 2023-02-16 00:00:00, 2023-02-17 00:00:00, 2023-02-18 00:00:00, 2023-02-19 00:00:00, 2023-02-20 00:00:00, 2023-02-21 00:00:00, 2023-02-22 00:00:00, 2023-02-23 00:00:00, 2023-02-24 00:00:00, 2023-02-25 00:00:00, 2023-02-26 00:00:00, 2023-02-27 00:00:00, 2023-02-28 00:00:00, 2024-02-29 00:00:00, March  Counts of PA<99.99, March Average Availability, 2023-03-01 00:00:00, 2023-03-02 00:00:00, 2023-03-03 00:00:00, 2023-03-04 00:00:00, 2023-03-05 00:00:00, 2023-03-06 00:00:00, 2023-03-07 00:00:00, 2023-03-08 00:00:00, 2023-03-09 00:00:00, 2023-03-10 00:00:00, 2023-03-11 00:00:00, 2023-03-12 00:00:00, 2023-03-13 00:00:00, 2023-03-14 00:00:00, 2023-03-15 00:00:00, 2023-03-16 00:00:00, 2023-03-17 00:00:00, 2023-03-18 00:00:00, 2023-03-19 00:00:00, 2023-03-20 00:00:00, 2023-03-21 00:00:00, ...]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 403 columns]\n",
      "*******************************\n",
      "Empty DataFrame\n",
      "Columns: [IHS Site ID, Tenant Site ID, NOC Group, cluster, Project, Priority, Vendor Name, Region, State, Site Name/ Address, Process No, Task No., Fault MTTR, Time Fault occured, Time Site on Air, Source of Escalation, Impact, Root Cause Analysis, Root Cause Type, Resolution, Diesel Level, MTTR, Exclusion (Y/N), Day, Week, Ghr, Mins, class]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "print(performance_inclusion.head(0))\n",
    "print('*******************************')\n",
    "print(performance_exclusion.head(0))\n",
    "print('*******************************')\n",
    "print(outages.head(0))\n",
    "\n",
    "#Check if data is properly loaded, especially the headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning for Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERFORMANCE CLEANING\n",
    "# For the performance dataframes, we need to keep just the site_id columns and the columns with performance [the columns with performance have dates as the column headers]\n",
    "# so what we would do is to create a function that checks if column header is a date\n",
    "\n",
    "# Function to check if a column name is a date\n",
    "def is_date(string):\n",
    "    try:\n",
    "        pd.to_datetime(string)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "\n",
    "# Create a variable that stores found columns\n",
    "date_columns_inc = [col for col in performance_inclusion.columns if is_date(col)]\n",
    "date_columns_exc = [col for col in performance_exclusion.columns if is_date(col)]\n",
    "\n",
    "# Add the above columns to the 'IHS Site ID' column\n",
    "columns_to_keep_inc = [\"IHS Site ID\"] + date_columns_inc\n",
    "columns_to_keep_exc = [\"IHS Site ID\"] + date_columns_exc\n",
    "\n",
    "# Create new dataframes with 'columns to keep'\n",
    "inc = performance_inclusion[columns_to_keep_inc]\n",
    "exc = performance_exclusion[columns_to_keep_exc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IHS Site ID</th>\n",
       "      <th>2023-01-01 00:00:00</th>\n",
       "      <th>2023-01-02 00:00:00</th>\n",
       "      <th>2023-01-03 00:00:00</th>\n",
       "      <th>2023-01-04 00:00:00</th>\n",
       "      <th>2023-01-05 00:00:00</th>\n",
       "      <th>2023-01-06 00:00:00</th>\n",
       "      <th>2023-01-07 00:00:00</th>\n",
       "      <th>2023-01-08 00:00:00</th>\n",
       "      <th>2023-01-09 00:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2023-12-22 00:00:00</th>\n",
       "      <th>2023-12-23 00:00:00</th>\n",
       "      <th>2023-12-24 00:00:00</th>\n",
       "      <th>2023-12-25 00:00:00</th>\n",
       "      <th>2023-12-26 00:00:00</th>\n",
       "      <th>2023-12-27 00:00:00</th>\n",
       "      <th>2023-12-28 00:00:00</th>\n",
       "      <th>2023-12-29 00:00:00</th>\n",
       "      <th>2023-12-30 00:00:00</th>\n",
       "      <th>2023-12-31 00:00:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IHS_ABE_0023B</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IHS_ABJ_0103B</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>91.688657</td>\n",
       "      <td>100</td>\n",
       "      <td>95.979167</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 367 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0    IHS Site ID 2023-01-01 00:00:00 2023-01-02 00:00:00 2023-01-03 00:00:00  \\\n",
       "0  IHS_ABE_0023B                 100                 100                 100   \n",
       "1  IHS_ABJ_0103B                 100                 100                 100   \n",
       "\n",
       "0 2023-01-04 00:00:00 2023-01-05 00:00:00 2023-01-06 00:00:00  \\\n",
       "0                 100                 100                 100   \n",
       "1                 100                 100                 100   \n",
       "\n",
       "0 2023-01-07 00:00:00 2023-01-08 00:00:00 2023-01-09 00:00:00  ...  \\\n",
       "0                 100                 100                 100  ...   \n",
       "1           91.688657                 100           95.979167  ...   \n",
       "\n",
       "0 2023-12-22 00:00:00 2023-12-23 00:00:00 2023-12-24 00:00:00  \\\n",
       "0                 NaT                 NaT                 NaT   \n",
       "1                 NaT                 NaT                 NaT   \n",
       "\n",
       "0 2023-12-25 00:00:00 2023-12-26 00:00:00 2023-12-27 00:00:00  \\\n",
       "0                 NaT                 NaT                 NaT   \n",
       "1                 NaT                 NaT                 NaT   \n",
       "\n",
       "0 2023-12-28 00:00:00 2023-12-29 00:00:00 2023-12-30 00:00:00  \\\n",
       "0                 NaT                 NaT                 NaT   \n",
       "1                 NaT                 NaT                 NaT   \n",
       "\n",
       "0 2023-12-31 00:00:00  \n",
       "0                 NaT  \n",
       "1                 NaT  \n",
       "\n",
       "[2 rows x 367 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exc.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PERFORMANCE CLEANING contd\n",
    "\n",
    "# We have out dataset with Site_IDs on first column and daily performances on subsequent columns, but we want to unpivot these performance from the site ID\n",
    "# This will enable us have just 3 columns with Site_IDs, Date, Performance\n",
    "# we will be using the melt method on pandas\n",
    "\n",
    "inc = pd.melt(inc, id_vars=['IHS Site ID'], var_name='Date', value_name='Performance')\n",
    "exc = pd.melt(exc, id_vars=['IHS Site ID'], var_name='Date', value_name='Performance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IHS Site ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>479824</th>\n",
       "      <td>IHS_KAN_1380B</td>\n",
       "      <td>2023-12-31 00:00:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479825</th>\n",
       "      <td>IHS_ZAM_0020B</td>\n",
       "      <td>2023-12-31 00:00:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          IHS Site ID                 Date Performance\n",
       "479824  IHS_KAN_1380B  2023-12-31 00:00:00         NaT\n",
       "479825  IHS_ZAM_0020B  2023-12-31 00:00:00         NaT"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exc.tail(2)\n",
    "\n",
    "# Some performance fields are empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also need to remove columns where performance is not available in our dataframe\n",
    "inc = inc.dropna(subset=['Performance'])\n",
    "exc = exc.dropna(subset=['Performance'])\n",
    "\n",
    "# And an extra column named 'Exclusions' to specify or diffrentiate inc and exc because we are going to merge data into one\n",
    "inc['Exclusions'] = 'Including'\n",
    "exc['Exclusions'] = 'Excluding'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IHS Site ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Performance</th>\n",
       "      <th>Exclusions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>221557</th>\n",
       "      <td>IHS_KAN_1380B</td>\n",
       "      <td>2023-06-17 00:00:00</td>\n",
       "      <td>100</td>\n",
       "      <td>Excluding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221558</th>\n",
       "      <td>IHS_ZAM_0020B</td>\n",
       "      <td>2023-06-17 00:00:00</td>\n",
       "      <td>100</td>\n",
       "      <td>Excluding</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          IHS Site ID                 Date Performance Exclusions\n",
       "221557  IHS_KAN_1380B  2023-06-17 00:00:00         100  Excluding\n",
       "221558  IHS_ZAM_0020B  2023-06-17 00:00:00         100  Excluding"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exc.tail(2)\n",
    "\n",
    "#Testing out df [We notices date is year 2023 instead of 2024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New dataframe is created from the merged dfs (inc and exc)\n",
    "performance = pd.concat([inc, exc],ignore_index=True)\n",
    "\n",
    "# Date Column is properly formated as a date\n",
    "performance['Date'] = pd.to_datetime(performance['Date'])\n",
    "\n",
    "# Some dates where mistakenly entered as 2023 instead of 2024, but since we know our data includes in 2024\n",
    "# We can handle that by adding a year to years in the df\n",
    "# Locate where we have 2023 and add 1\n",
    "performance.loc[performance['Date'].dt.year == 2023, 'Date'] += pd.DateOffset(years=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IHS Site ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Performance</th>\n",
       "      <th>Exclusions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>360011</th>\n",
       "      <td>IHS_KAN_1380B</td>\n",
       "      <td>2024-06-17</td>\n",
       "      <td>100</td>\n",
       "      <td>Excluding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360012</th>\n",
       "      <td>IHS_ZAM_0020B</td>\n",
       "      <td>2024-06-17</td>\n",
       "      <td>100</td>\n",
       "      <td>Excluding</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          IHS Site ID       Date Performance Exclusions\n",
       "360011  IHS_KAN_1380B 2024-06-17         100  Excluding\n",
       "360012  IHS_ZAM_0020B 2024-06-17         100  Excluding"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning for Outages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTAGES CLEANING\n",
    "# For the otages dataframes, select needed columns\n",
    "\n",
    "outages = outages[['IHS Site ID',\n",
    "       'Process No', 'Task No.', 'Fault MTTR', 'Time Fault occured',\n",
    "       'Time Site on Air', 'Source of Escalation', 'Impact',\n",
    "       'Root Cause Analysis', 'Root Cause Type', 'Resolution', 'Diesel Level','Exclusion (Y/N)', 'Day', 'Week', 'Ghr', 'Mins', 'class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The derive_rca function is designed to classify the root cause of an issue based on the content of the Root Cause Analysis column in a dataframe. \n",
    "# It returns a categorized string based on keywords found in the analysis text.\n",
    "\n",
    "def derive_rca(row):\n",
    "    if pd.isnull(row['Root Cause Analysis']):\n",
    "        return 'Unknown'  # Handle NaN values appropriately\n",
    "    \n",
    "    rca = row['Root Cause Analysis'].lower()\n",
    "    \n",
    "    if 'access' in rca:\n",
    "        return 'Access'\n",
    "    elif 'fuel' in rca or 'diesel' in rca or 'separator' in rca:\n",
    "        return 'Diesel Related'\n",
    "    elif 'hybrid' in rca:\n",
    "        return 'Hybrid issues'\n",
    "    elif 'compression' in rca:\n",
    "        return 'Loss Compression'\n",
    "    elif 'servicing' in rca or 'plan' in rca or 'activi' in rca:\n",
    "        return 'Planned activity'\n",
    "    elif 'grid' in rca:\n",
    "        return 'Grid'\n",
    "    elif 'rectif' in rca:\n",
    "        return 'Rectifier'\n",
    "    elif 'theft' in rca or 'vanda' in rca:\n",
    "        return 'Theft/Vandalism'\n",
    "    elif 'dg' in rca or 'cable' in rca:\n",
    "        return 'Spares Related'\n",
    "    elif 'ats' in rca:\n",
    "        return 'ATS'\n",
    "    elif 'breaker' in rca:\n",
    "        return 'Breaker'\n",
    "    else:\n",
    "        return 'Other Issues'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Fault MTTR' from seconds to 'HH:MM:SS' format if it's numeric\n",
    "outages['Fault MTTR'] = outages['Fault MTTR'].apply(lambda x: pd.to_datetime(x, unit='s').strftime('%H:%M:%S') if isinstance(x, (int, float)) else x)\n",
    "\n",
    "# Convert 'Time Fault occured' to datetime\n",
    "outages['Time Fault occured'] = pd.to_datetime(outages['Time Fault occured'])\n",
    "\n",
    "# Convert 'Time Site on Air' to datetime\n",
    "outages['Time Site on Air'] = pd.to_datetime(outages['Time Site on Air'])\n",
    "\n",
    "# Calculate the difference between 'Time Site on Air' and 'Time Fault occured'\n",
    "outages['confirm MTTR'] = outages['Time Site on Air'] - outages['Time Fault occured']\n",
    "\n",
    "# Convert the time difference to string format\n",
    "outages['confirm MTTR'] = outages['confirm MTTR'].apply(lambda x: str(x))\n",
    "\n",
    "# Convert the time difference string back to timedelta\n",
    "outages['confirm MTTR'] = pd.to_timedelta(outages['confirm MTTR'])\n",
    "\n",
    "# Extract date part from 'Day'\n",
    "outages['Day'] = pd.to_datetime(outages['Day']).dt.date\n",
    "\n",
    "# Define a threshold of 1 hour 59 minutes\n",
    "threshold = pd.Timedelta(hours=1, minutes=59)\n",
    "\n",
    "# Determine if 'confirm MTTR' exceeds the threshold\n",
    "outages['SLA Status'] = outages['confirm MTTR'].apply(lambda x: 'Breached' if x > threshold else 'Achieved')\n",
    "\n",
    "# Apply the derive_rca function to each row to derive 'RCA [Derived]'\n",
    "outages['RCA [Derived]'] = outages.apply(derive_rca, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IHS Site ID</th>\n",
       "      <th>Process No</th>\n",
       "      <th>Task No.</th>\n",
       "      <th>Fault MTTR</th>\n",
       "      <th>Time Fault occured</th>\n",
       "      <th>Time Site on Air</th>\n",
       "      <th>Source of Escalation</th>\n",
       "      <th>Impact</th>\n",
       "      <th>Root Cause Analysis</th>\n",
       "      <th>Root Cause Type</th>\n",
       "      <th>...</th>\n",
       "      <th>Diesel Level</th>\n",
       "      <th>Exclusion (Y/N)</th>\n",
       "      <th>Day</th>\n",
       "      <th>Week</th>\n",
       "      <th>Ghr</th>\n",
       "      <th>Mins</th>\n",
       "      <th>class</th>\n",
       "      <th>confirm MTTR</th>\n",
       "      <th>SLA Status</th>\n",
       "      <th>RCA [Derived]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20883</th>\n",
       "      <td>IHS_ABJ_1057A</td>\n",
       "      <td>0</td>\n",
       "      <td>NOCINC0002416315</td>\n",
       "      <td>00:35:04</td>\n",
       "      <td>2024-06-17 23:24:55</td>\n",
       "      <td>2024-06-17 23:59:59</td>\n",
       "      <td>0</td>\n",
       "      <td>Site Down</td>\n",
       "      <td>Rectifier Module</td>\n",
       "      <td>Rectifier</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>2024-06-17</td>\n",
       "      <td>Week 25</td>\n",
       "      <td>0</td>\n",
       "      <td>35.066667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:35:04</td>\n",
       "      <td>Achieved</td>\n",
       "      <td>Rectifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20884</th>\n",
       "      <td>IHS_PLA_0708E</td>\n",
       "      <td>0</td>\n",
       "      <td>NOCINC0002413718</td>\n",
       "      <td>00:15:22</td>\n",
       "      <td>2024-06-17 21:16:57</td>\n",
       "      <td>2024-06-17 21:32:19</td>\n",
       "      <td>0</td>\n",
       "      <td>Site Down</td>\n",
       "      <td>National Grid - Grid Outage Issue</td>\n",
       "      <td>Grid</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>2024-06-17</td>\n",
       "      <td>Week 25</td>\n",
       "      <td>0</td>\n",
       "      <td>15.366667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:15:22</td>\n",
       "      <td>Achieved</td>\n",
       "      <td>Grid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20885</th>\n",
       "      <td>IHS_ADA_0913B</td>\n",
       "      <td>0</td>\n",
       "      <td>NOCINC0002413892</td>\n",
       "      <td>00:45:31</td>\n",
       "      <td>2024-06-17 16:29:36</td>\n",
       "      <td>2024-06-17 17:15:07</td>\n",
       "      <td>0</td>\n",
       "      <td>Site Down</td>\n",
       "      <td>Hybrid Software</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>2024-06-17</td>\n",
       "      <td>Week 25</td>\n",
       "      <td>0</td>\n",
       "      <td>45.516667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:45:31</td>\n",
       "      <td>Achieved</td>\n",
       "      <td>Hybrid issues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         IHS Site ID Process No          Task No. Fault MTTR  \\\n",
       "20883  IHS_ABJ_1057A          0  NOCINC0002416315   00:35:04   \n",
       "20884  IHS_PLA_0708E          0  NOCINC0002413718   00:15:22   \n",
       "20885  IHS_ADA_0913B          0  NOCINC0002413892   00:45:31   \n",
       "\n",
       "       Time Fault occured    Time Site on Air  Source of Escalation  \\\n",
       "20883 2024-06-17 23:24:55 2024-06-17 23:59:59                     0   \n",
       "20884 2024-06-17 21:16:57 2024-06-17 21:32:19                     0   \n",
       "20885 2024-06-17 16:29:36 2024-06-17 17:15:07                     0   \n",
       "\n",
       "          Impact                Root Cause Analysis Root Cause Type  ...  \\\n",
       "20883  Site Down                   Rectifier Module       Rectifier  ...   \n",
       "20884  Site Down  National Grid - Grid Outage Issue            Grid  ...   \n",
       "20885  Site Down                    Hybrid Software          Hybrid  ...   \n",
       "\n",
       "      Diesel Level  Exclusion (Y/N)         Day     Week Ghr       Mins  \\\n",
       "20883            0                N  2024-06-17  Week 25   0  35.066667   \n",
       "20884            0                N  2024-06-17  Week 25   0  15.366667   \n",
       "20885            0                N  2024-06-17  Week 25   0  45.516667   \n",
       "\n",
       "       class    confirm MTTR SLA Status  RCA [Derived]  \n",
       "20883    NaN 0 days 00:35:04   Achieved      Rectifier  \n",
       "20884    NaN 0 days 00:15:22   Achieved           Grid  \n",
       "20885    NaN 0 days 00:45:31   Achieved  Hybrid issues  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outages.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaned, Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance.to_csv('C:/Users/mayow/OneDrive/My Projects [data analytics]/Telecommunications Site Outages Analysis and Reporting/assets/datasets/performance.csv', index=False)\n",
    "outages.to_csv('C:/Users/mayow/OneDrive/My Projects [data analytics]/Telecommunications Site Outages Analysis and Reporting/assets/datasets/outages.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mayowa-data-analytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
